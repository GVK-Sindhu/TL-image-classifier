{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06296c20-a164-407b-9b33-658d036772c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba0a926-8955-4b60-906c-b711beb5dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"data/train\"\n",
    "val_dir = \"data/val\"\n",
    "test_dir = \"data/test\"\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "num_classes = 5  # tf_flowers has 5 classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e8fed2-e71e-4c94-81c2-11ac6e7b9539",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m val_gen = ImageDataGenerator(rescale=\u001b[32m1\u001b[39m/\u001b[32m255.0\u001b[39m)\n\u001b[32m      9\u001b[39m test_gen = ImageDataGenerator(rescale=\u001b[32m1\u001b[39m/\u001b[32m255.0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m train_data = \u001b[43mtrain_gen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcategorical\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m val_data = val_gen.flow_from_directory(\n\u001b[32m     19\u001b[39m     val_dir,\n\u001b[32m     20\u001b[39m     target_size=img_size,\n\u001b[32m     21\u001b[39m     batch_size=batch_size,\n\u001b[32m     22\u001b[39m     class_mode=\u001b[33m\"\u001b[39m\u001b[33mcategorical\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     23\u001b[39m )\n\u001b[32m     25\u001b[39m test_data = test_gen.flow_from_directory(\n\u001b[32m     26\u001b[39m     test_dir,\n\u001b[32m     27\u001b[39m     target_size=img_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     31\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\python\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1136\u001b[39m, in \u001b[36mImageDataGenerator.flow_from_directory\u001b[39m\u001b[34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[39m\n\u001b[32m   1118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflow_from_directory\u001b[39m(\n\u001b[32m   1119\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1120\u001b[39m     directory,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1134\u001b[39m     keep_aspect_ratio=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1135\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\python\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:456\u001b[39m, in \u001b[36mDirectoryIterator.__init__\u001b[39m\u001b[34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[32m    455\u001b[39m     classes = []\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[32m    457\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(os.path.join(directory, subdir)):\n\u001b[32m    458\u001b[39m             classes.append(subdir)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: 'data/train'"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1/255.0,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1/255.0)\n",
    "test_gen = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_data = val_gen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_data = test_gen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_names = list(train_data.class_indices.keys())\n",
    "print(\"Classes:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0473d091-f4d7-4534-9c95-30b0f407eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Phase 1: Freeze base model\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b3b47-5bd3-4567-904d-f7ae8c8fc971",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_accuracy\"),\n",
    "    EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history1 = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f645b1-4f8e-4547-b4d0-710f501ef3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the top 50 layers of the base model\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),  # Very low LR\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history2 = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3b059-7aff-4fa3-a38b-a51910b5da40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afbe715-12a5-4fb8-8ca1-f2a06e0f3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(acc, label=\"train accuracy\")\n",
    "    plt.plot(val_acc, label=\"val accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(loss, label=\"train loss\")\n",
    "    plt.plot(val_loss, label=\"val loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history1, \"Phase 1 Training\")\n",
    "plot_history(history2, \"Phase 2 Fine-tuning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551273d1-d31b-4b13-9a0f-038bb29eb404",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best_model.h5\")\n",
    "\n",
    "pred_probs = model.predict(test_data)\n",
    "y_pred = np.argmax(pred_probs, axis=1)\n",
    "y_true = test_data.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2bf7db-5e39-4bc0-af1a-04aa7bb5958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    cmap=\"Blues\"\n",
    ")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55effe97-edfb-4f5c-a608-f96218901c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_gradcam(model, img_array, layer_name):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], \n",
    "        [model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        pred_index = tf.argmax(predictions[0])\n",
    "        loss = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.zeros(conv_outputs.shape[0:2])\n",
    "\n",
    "    for i in range(conv_outputs.shape[-1]):\n",
    "        heatmap += pooled_grads[i] * conv_outputs[:, :, i]\n",
    "\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= tf.math.reduce_max(heatmap)\n",
    "\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173632a4-e85e-445d-9ec0-764cc89c6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Choose any test image path manually\n",
    "img_path = r\"D:\\transfer-learning-image-classifier\\data\\test\\daisy\\daisy_3.jpg\"\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "layer_name = \"conv5_block3_out\"  # Last convolutional block of ResNet50\n",
    "\n",
    "heatmap = get_gradcam(model, img_array, layer_name)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Resize heatmap\n",
    "heatmap = cv2.resize(heatmap, (224, 224))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "# Apply color map\n",
    "heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "# Convert original image to uint8\n",
    "img_uint8 = (img_array[0] * 255).astype(\"uint8\")\n",
    "\n",
    "# Overlay heatmap on image\n",
    "overlay = cv2.addWeighted(heatmap_color, 0.4, img_uint8, 0.6, 0)\n",
    "\n",
    "plt.imshow(overlay)\n",
    "plt.title(\"Grad-CAM\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64843750-41e4-41bc-b9f7-6ece5d21dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "\n",
    "baseline.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "baseline.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f93d4-6979-4205-8c1d-ee69d406c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_base = baseline.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d871b-2ec6-4393-ba02-ae0650490af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_pred = baseline.predict(test_data)\n",
    "baseline_y_pred = np.argmax(baseline_pred, axis=1)\n",
    "\n",
    "print(\"Baseline Model Performance:\\n\")\n",
    "print(classification_report(y_true, baseline_y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceeabc2-12f5-41d1-8a4c-0f9a91632ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/final_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9977db6e-d4c3-4a12-9ff0-3aa7c40c62df",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(\"models/best_model.h5\")\n",
    "best_model.save(\"models/final_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0e795-bda7-45fd-b2d1-6fe4a914062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "best_model = tf.keras.models.load_model(\"models/best_model.h5\")\n",
    "best_model.save(\"models/final_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b8341-87a8-42f3-833f-088d684041b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Acc\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.savefig(\"visualizations/accuracy_curve.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.savefig(\"visualizations/loss_curve.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c915fb74-4d05-49bd-a27b-ad22670942f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m,\u001b[32m5\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m plt.plot(\u001b[43mhistory\u001b[49m.history[\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m], label=\u001b[33m\"\u001b[39m\u001b[33mTrain Acc\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m plt.plot(history.history[\u001b[33m\"\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m\"\u001b[39m], label=\u001b[33m\"\u001b[39m\u001b[33mVal Acc\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m plt.legend()\n",
      "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Acc\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.savefig(\"visualizations/accuracy_curve.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.savefig(\"visualizations/loss_curve.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa741523-d08b-44bd-910d-e7633231e04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization folder ready.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "print(\"Visualization folder ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f65064b-4456-4a09-b4d0-8eddc867f9c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m cm = confusion_matrix(\u001b[43my_true\u001b[49m, y_pred)\n\u001b[32m      7\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m,\u001b[32m6\u001b[39m))\n\u001b[32m      8\u001b[39m sns.heatmap(cm, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, fmt=\u001b[33m\"\u001b[39m\u001b[33md\u001b[39m\u001b[33m\"\u001b[39m, cmap=\u001b[33m\"\u001b[39m\u001b[33mBlues\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m             xticklabels=class_names, yticklabels=class_names)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "\n",
    "plt.savefig(\"visualizations/confusion_matrix.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved: visualizations/confusion_matrix.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b612b09f-f7d9-4fb7-8104-dca8b18795f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data/test'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_data = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocessing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/test\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\python\\Lib\\site-packages\\keras\\src\\utils\\image_dataset_utils.py:265\u001b[39m, in \u001b[36mimage_dataset_from_directory\u001b[39m\u001b[34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, format, verbose)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    264\u001b[39m     seed = np.random.randint(\u001b[32m1e6\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m image_paths, labels, class_names = \u001b[43mdataset_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label_mode == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) != \u001b[32m2\u001b[39m:\n\u001b[32m    277\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    278\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mWhen passing `label_mode=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`, there must be exactly 2 \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    279\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    280\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\python\\Lib\\site-packages\\keras\\src\\utils\\dataset_utils.py:739\u001b[39m, in \u001b[36mindex_directory\u001b[39m\u001b[34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels == \u001b[33m\"\u001b[39m\u001b[33minferred\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    738\u001b[39m     subdirs = []\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[32m    740\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m path_module.isdir(path_module.join(directory, subdir)):\n\u001b[32m    741\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subdir.startswith(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: 'data/test'"
     ]
    }
   ],
   "source": [
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"data/test\",\n",
    "    image_size=(224,224),\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f09358dd-c767-479d-ad1e-db19a124b972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\transfer-learning-image-classifier\\\\notebooks'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a6b4dc-1740-410d-b41d-03b437c1b445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 556 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../data/test\",\n",
    "    image_size=(224,224),\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "173487b3-ad62-4174-88c1-c32d5f7a65f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = test_data.class_names\n",
    "class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15d01dc7-dde5-4d9f-8585-c6dd1cfded82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"../models/best_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18a2e745-bb59-4499-bdcf-b8d5f6a26a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 6s/step\n",
      "Shapes: (556,) (556,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_true = []\n",
    "for _, labels in test_data:\n",
    "    y_true.extend(labels.numpy())\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "pred = model.predict(test_data)\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "\n",
    "print(\"Shapes:\", y_true.shape, y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee9c50-a943-4994-802b-d4557df16aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a04666-703d-46c0-9405-8d0d17489f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    ")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "\n",
    "plt.savefig(\"../visualizations/confusion_matrix.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"Confusion matrix saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "538c77ef-92d5-4d73-9fa5-7a0f0c7181c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3798429895.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m../data/test/daisy/image_003.jpg\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "../data/test/daisy/image_003.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75bf3761-bc62-4d75-9612-680c87d3c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../data/test/daisy/daisy_3.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dd58569-dd4a-4dec-a62d-bde6ebd91f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_gradcam(model, img_array, layer_name):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=model.inputs,\n",
    "        outputs=[model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        pred_index = tf.argmax(predictions[0])\n",
    "        pred_score = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(pred_score, conv_outputs)[0]\n",
    "\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6601017-00d9-4e37-9f7d-4fbbfc6383c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Lib\\site-packages\\keras\\src\\models\\functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input_layer']\n",
      "Received: inputs=Tensor(shape=(1, 224, 224, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m img_array = np.expand_dims(img_array, axis=\u001b[32m0\u001b[39m) / \u001b[32m255.0\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Generate Grad-CAM\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m heatmap = \u001b[43mget_gradcam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconv5_block3_out\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ResNet50 last conv layer\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mget_gradcam\u001b[39m\u001b[34m(model, img_array, layer_name)\u001b[39m\n\u001b[32m     23\u001b[39m heatmap = np.maximum(heatmap, \u001b[32m0\u001b[39m)\n\u001b[32m     24\u001b[39m heatmap /= np.max(heatmap)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mheatmap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "# Load an image\n",
    "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "# Generate Grad-CAM\n",
    "heatmap = get_gradcam(model, img_array, layer_name=\"conv5_block3_out\")  # ResNet50 last conv layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ab2af8f-b7c1-476f-a790-fbfcd3e6b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_gradcam(model, img_array, layer_name):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=model.inputs,\n",
    "        outputs=[model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        pred_index = tf.argmax(predictions[0])\n",
    "        pred_score = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(pred_score, conv_outputs)[0]\n",
    "\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abdbf320-1da8-4ca5-911f-53b4a00d429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "# Generate Grad-CAM\n",
    "heatmap = get_gradcam(model, img_array, layer_name=\"conv5_block3_out\")  # ResNet50 last conv layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51186347-ea44-47b3-9930-670ed5a29c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad-CAM saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Resize and colorize heatmap\n",
    "heatmap = cv2.resize(heatmap, (224, 224))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "# Original image\n",
    "orig = (img_array[0] * 255).astype(\"uint8\")\n",
    "\n",
    "# Blend heatmap with original image\n",
    "overlay = cv2.addWeighted(orig, 0.6, heatmap_color, 0.4, 0)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(overlay)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Grad-CAM Visualization\")\n",
    "plt.savefig(\"../visualizations/gradcam_example.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"Grad-CAM saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2cbb01-4b46-426e-884c-194b7ebcb9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
